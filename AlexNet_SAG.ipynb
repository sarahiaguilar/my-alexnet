{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet_Aguilar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wgnacYjLhV3"
      },
      "source": [
        "# Implementation of AlexNet in Keras over Tensorflow in Python\n",
        "### by Sarahí Aguilar\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAMAFOndMi1d"
      },
      "source": [
        "### About AlexNet overall architecture\n",
        "\n",
        "AlexNet contains eight layers with weights; the first five are convolutional and the remaining three are fullyconnected. The output of the last  fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels. This network maximizes the multinomial logistic regression objective, which is equivalent to maximizing the average across training cases of the log-probability of the correct label under the prediction distribution.\n",
        "\n",
        "The kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel maps in the previous layer which reside on the same GPU. The kernels of the third convolutional layer are connected to all kernel maps in the second layer. The neurons in the fullyconnected layers are connected to all neurons in the previous layer. Response-normalization layers follow the first and second convolutional layers. Max-pooling layers, follow both response-normalization layers as well as the fifth convolutional layer. The ReLU\n",
        "non-linearity is applied to the output of every convolutional and fully-connected layer.\n",
        "\n",
        "The first convolutional layer filters the 32×32×3 input image with 96 kernels of size 11×11×3 with a stride of 4 pixels (this is the distance between the receptive field centers of neighboring neurons in a kernel map). The second convolutional layer takes as input the (response-normalized and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48.\n",
        "\n",
        "The third, fourth, and fifth convolutional layers are connected to one another without any intervening pooling or normalization layers. The third convolutional layer has 384 kernels of size 3 × 3 × 256 connected to the (normalized, pooled) outputs of the second convolutional layer. The fourth\n",
        "convolutional layer has 384 kernels of size 3 × 3 × 192 , and the fifth convolutional layer has 256 kernels of size 3 × 3 × 192. The fully-connected layers have 4096 neurons each.\n",
        "\n",
        "Source: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cOz443ksES"
      },
      "source": [
        "![picture](https://raw.githubusercontent.com/sarahiaguilar/my-alexnet/main/alexnet_architecture.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdKsD_CRL4ha"
      },
      "source": [
        "#### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJIixSfokMaT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoguKvSQMBsl"
      },
      "source": [
        "#### Importing Cifar10 dataset\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
        "\n",
        "Source: https://www.cs.toronto.edu/~kriz/cifar.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGP12CrZehlb"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAMs0ff0lzO9"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT4Au6HVmN07",
        "outputId": "282e7dde-a058-475a-b48b-ed92cdef91cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Previewing random example image\n",
        "example_image = train_images[111, :, :, :]\n",
        "plt.imshow(example_image)\n",
        "example_image.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb9ElEQVR4nO2da6ycV3WG3zWXc53jWxxf4lwckgBJAwmpSUEYGm5pipACUoXgB8oPhFFFpFLRHxGVIJX6A1ABoQpRmRIRKkpIgYi0RFyagiIQCpxA4lxMsGOc2I7t4+vxuZ+Z+VZ/zFhyov2uczznnBmH/T6S5Tl7zf72+vZ8a76Z/c5a29wdQog/fUq9dkAI0R0U7EJkgoJdiExQsAuRCQp2ITJBwS5EJlSW0tnMbgPwZQBlAP/u7p+Nnj88strXrt9ArIEESEwO475Fx3ul04lcyqdq2Yd6JXBBnRa9vjnVcvo+ffL4GCYnxpOvdsfBbmZlAF8B8G4ABwH8xswedPdnWJ+16zfgzru/lDZ6k47FLjgPPphUvE5tneKejhjW3rJFL1kUgbyfeSPoxzp1Fu3N4NyKqGNH0cQ7RfNowbmxftHxPJqroF8R+ciPCPN0GNYLfrzNawaS7Z//9N/TPkv5GH8zgL3uvs/d5wHcB+D2JRxPCLGCLCXYtwA4cM7fB9ttQogLkBVfoDOzHWY2amajUxPjKz2cEIKwlGA/BOCyc/6+tN32Etx9p7tvc/dtwyOrlzCcEGIpLCXYfwPgGjO70sz6AHwQwIPL45YQYrnpeDXe3RtmdieAH6Mlvd3j7k9HfRoFcHLm/Fe0GU0rU1spUvKildiOVs87XY3vDA9WaRnWofZWdNiPetjx3HOWezU+VBKi1fiC6xPR/Fea6Xuulfi9ePfYgWT77Nw8H4daFoG7PwTgoaUcQwjRHfQLOiEyQcEuRCYo2IXIBAW7EJmgYBciE5a0Gn/+GFBKD1ly/r7DxA63Ku1TBGkanUtvy3y8QDKySBkKJMdA8+J9AkKFqpNTC3NMOpQpg3ksqEwZJRpFYwWmMu9YCpOl0q9nEBKYK9LJUNEc6s4uRCYo2IXIBAW7EJmgYBciExTsQmRCV1fjDY4+kPJTHhQ5osuj0dJuUOaK9+qoVpvHmRPc0uHqcylK/GCmUDGIRgtUjQ7qBkZ0WnqqFNyzmvR6435ESSud+hgN2CgRHwPRxcqkNFkgJejOLkQmKNiFyAQFuxCZoGAXIhMU7EJkgoJdiEzosvQGVIgE4dH+IkRNKDNZBQBCW6ecv+8eSCGRdGVB4kSUVEHHCqWwyBjt+7LMCUWdzofxe1aJSLDR1mFcv1xAeutwh5+CFUwMEp4s3o8nie7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyIQlSW9mth/ABFo6V8Pdty3QAQWpG+elcLv682wHOq25FsElts62SAqlmrBWW/AeTU47VOtCOanTunCdjBVIXtFQ0bVDFaqgbl2w7dJKZL2VScanB/fikrP6i8E2U9SyeN7u7seX4ThCiBVEH+OFyISlBrsD+ImZPWZmO5bDISHEyrDUj/Hb3f2QmW0A8FMz+727P3LuE9pvAjsAYPW6DUscTgjRKUu6s7v7ofb/YwAeAHBz4jk73X2bu28bGlm9lOGEEEug42A3s2EzGzn7GMCtAJ5aLseEEMvLUj7GbwTwQFtuqAD4T3f/UdzFaCZPEe93xI9HOf+soAUhfniHkkuHuwzFgiPzpcPakOG2XEaKHgKApee/aHDvm806tc3NTFLb8OAQ94PIaFE2IoxnTDYagY9zvN/w4DAfroMsRro3VHBaHQe7u+8DcEOn/YUQ3UXSmxCZoGAXIhMU7EJkgoJdiExQsAuRCV3f661CCkE6kWraHZOUimAzrIBwZ7awUGLaVkSFEsNMrkgPC7KkOpAp4/KbQaZUIAsVwa2iKKVfz2YgXZ0+eYTa5qbGqa3RN0htTZbBVuHn1WjOUlv0Wh85epLarr2WC1fs0uczBZjNk3bt9SZE9ijYhcgEBbsQmaBgFyITFOxCZEJXV+MBoExWM5vRCjMhWnmMVrrjkc5/S6O4TltnNcvCNJ6oBh2ZEwvW48M8noJ7EnWbm55Otk8cP0z7jJ94kY/V4Ek38w0+x9ON9Kr1fHOO9oGn+wBApa+P2mamuY9z45uorT4/lWw/Ns6Tf9aQ5J9mk/ugO7sQmaBgFyITFOxCZIKCXYhMULALkQkKdiEyoevSG5N5wt2f2LECW8fyWjhg2honz3AadS7xWJm/NA4u/wBp6aUU1FUrCp74MT55itoG+tdSmzXS440d+j3tM3b4eWpbVVtHbSWyfRIATMykZS04n49yMFczwVi1VbxU+th+ft6NejqB5vmjJ2ifY32rku1zM2nJE9CdXYhsULALkQkKdiEyQcEuRCYo2IXIBAW7EJmwoPRmZvcAeC+AMXe/vt22DsB3AGwFsB/AB9ydazRncYeTrJwo84pmhwVZb7GS11lduCaRkxp1Ll1VKnyKz5zmNcuGa2lpBQCqA9HLRmr8Nbkkc+TFfdR24IXnqO2Sja+mtjXDaf+PB2OdGuNZb81ZPse1Gt/+6eTYoWT7YF+V9ikFsly0U5M1uCw3DV4vsb+azm4rps7QPidOpsOtQbL8gMXd2b8B4LaXtd0F4GF3vwbAw+2/hRAXMAsGe3u/9Zffgm4HcG/78b0A3rfMfgkhlplOv7NvdPezVQiOoLWjqxDiAmbJC3Te+q0o/aJrZjvMbNTMRqcmee1vIcTK0mmwHzWzzQDQ/n+MPdHdd7r7NnffNlxb3eFwQoil0mmwPwjgjvbjOwD8YHncEUKsFIuR3r4N4BYA683sIIDPAPgsgPvN7CMAngfwgcUM5u5ozKcL/VmFSyFG35OCbLMOCli2xuI0PC0bTk9yiaQRFEqs1/kGP31r+KcgCwoiNuoTyfYX/rib9tn33FPUdmacZ15NnuAFETdfvDnZPjF+mvYZrPZT26pajdvWctuBA3uT7c2Z9DwBQF+Zy2TVAe7j7DSfjy2XXE5tZ8bTMtr8NL+u+irpjMOo+OmCwe7uHyKmdy7UVwhx4aBf0AmRCQp2ITJBwS5EJijYhcgEBbsQmdDlgpMOJwX7SpGMRvsEQllnyltYPLJEbM063zdscoLLJ4Nkvy4AqM+RQokAylXu4/49aYnt2aceo31mp7gcVqlwGao+zWW5saMzyfZajRepnD7F5bDXvPZ6ahsY4bLt00/vSrbXZ/lrVirxcy7qPCNu43p+bre881Zqe+i/70u2z04foH36V6djIpKOdWcXIhMU7EJkgoJdiExQsAuRCQp2ITJBwS5EJnRVejMAJfL2EkkGzBYXlexQewv6lcmGdKUS7zMb7L1Vn+NFFIcHuZy0f++z1Lbn2SeT7c1ZnpFVLbicNH2K90M/t02Sveo2rLmU9pmvc7nxuX18H7hrb3gNtcHTMlrR5FfPfD2QX4Pr44pXXUNt173uJmr7+c8eTrZXKoO0jzdJYdFIOqYWIcSfFAp2ITJBwS5EJijYhcgEBbsQmdD1RJgKqeNmDb763KykV04dfLudSpRXE6xYFgU/ZpNsrTTe4KvSL558gfsxyZMxRshYADC+l2+hNHsmvaUUq58HAEPgc9+Y5/2KoL5e30D6NTsdbHm1YUu6bh0A1Natp7bR0SeorVpPn9uGAX68uRmuCsw5D5n1IxdTW7MRqDwsDAs+VjD1FN3ZhcgEBbsQmaBgFyITFOxCZIKCXYhMULALkQmL2f7pHgDvBTDm7te32+4G8FEAx9pP+5S7P7TwcA4gveVRpTRAe5UsLUN1kjwDAEWQ+BEekxgv2rCB9jl+6gi1PTv2DLUdefzX1FZznkDTIAkSs1PpmnAA0Czz+WgUXDJqzPPtq5wkoGzZzOu0bX/7X1LbNde/jtp+8qMfUtuaIi29jQS+l4Ktw8YDafbAi0ep7cEf8vCYnU6/NmvXrKN9ZmbZNcCv4MXc2b8B4LZE+5fc/cb2v0UEuhCilywY7O7+CAD+SwghxCuCpXxnv9PMdpnZPWbGP5sJIS4IOg32rwK4CsCNAA4D+AJ7opntMLNRMxudmuR1wYUQK0tHwe7uR9296a0dH74G4ObguTvdfZu7bxuujXTqpxBiiXQU7GZ2bsbC+wE8tTzuCCFWisVIb98GcAuA9WZ2EMBnANxiZjeipaXtB/CxxQw2OzeD3XvS7wtXXv1q2q9UnyfO8feq/qEatRnT0AB4UGOs1CDbUE0HKUjGp/jPbtlObePzXCp79vFfUVtxJu2jz3J5ba7KZahykFlYBLJcvZEe783b30r7bN/+NmqbYNcAgOte/3pqq11/Q7L95EG+tdJgjdd+GxvnX0UHgsy8SpVLy7//3W+S7VxeA4LETe7DQk9w9w8lmr9+/kMJIXqJfkEnRCYo2IXIBAW7EJmgYBciExTsQmRCVwtOTkycwf/9/MdJ25pnfkf7jRCJZ2iQy2ubt15JbUNDQ9Q2G8gdzdm0xFYEGVSHDu+htlMFl9eueP211Lb91ndS25HnDifb9z76OO0zPcaztQZIFh0ADAxyOWlmPv2a1fnhcPQET8Fokq23AODV115HbUPldPZd5XreZ+zEMWq7tMyLc65dv4nazpwep7YH/iMt5x07cYr2Wb0q/QM1bf8khFCwC5ELCnYhMkHBLkQmKNiFyAQFuxCZ0FXpzQzor6bfX06SPcoA4BTJeNpgPCNrav9z1NZKw09TBNLF/OR0sv2Ki3ihnku4UoO+UzyD6tkHHqC2U9dzWW7Lu29Ntt9w+eV8rO/9gNom9vJ5nHMuh/UNrkq2T85xmfJfv/JVavvzm99IbW99O8+kQyWt9UV7AdZW8UKPKPg5N2b43n3N2aA4J8mMbDq/F3eS9aY7uxCZoGAXIhMU7EJkgoJdiExQsAuRCV1djV+9ahX+6l3vTtr2n5mk/Y7MnEm2Dw/xWmFDQc2viPk6XzU9uv/5ZPuM8Rp06/v4FA+O8Gq7I3MXU5sF2STj01PJ9tNTPMFndjI9vwAw2NdHbUWZn9vai9L12KaDVelTZ7g6MfrYY9RW7Q+SU1an57hi6QSZlo0fL9ryanCAX4/zc3yl3ktpX6r9/BquktfFgrqMurMLkQkKdiEyQcEuRCYo2IXIBAW7EJmgYBciExaz/dNlAL4JYCNa2z3tdPcvm9k6AN8BsBWtLaA+4O68aBYALwCfTyehrF67gfarvfGmZHujyhNaVgeyxdDwMLVZUOusb/SJZPvJ3+2ifQbL/HhHjvHpGurnL836Wj+1zU6mJbb5saCeWT+X1/rWpBNaAMAGuXS4YcuWZPuWy6+gfd61micU7d+3l9oO7H+B2k4MpueqVuPnValyCe1oUK9v3Truf3+Vz/FlW69KtpdLXGIdGUjfpw++cJD2WcydvQHgk+5+HYA3Afi4mV0H4C4AD7v7NQAebv8thLhAWTDY3f2wu/+2/XgCwG4AWwDcDuDe9tPuBfC+lXJSCLF0zus7u5ltBfAGAI8C2OjuZ+sWH0HrY74Q4gJl0cFuZjUA3wPwCXd/ye8rvVWsOplOb2Y7zGzUzEZnZ9LFH4QQK8+igt3MqmgF+rfc/fvt5qNmtrlt3wxgLNXX3Xe6+zZ33zYwyDdnEEKsLAsGu5kZWvux73b3L55jehDAHe3HdwDgtY2EED1nMVlvbwHwYQBPmtnZPYQ+BeCzAO43s48AeB7ABxY60NTkJH71i18mbY1Aett65SXJ9vImLnXMB1sTlYgcAwBlkoEEAJtufF16rEme0dSY519dTpw+TW3TRFoBgP41q/l40+msrPIslymHN6bnFwAqBZd/miU+jzUiva254lLap0xq/AHA8Wmembdx/UXU5iSLsTbCpbehEX5d1Tbx63QguK64AAvMk7qMh0+nt/ICgKqlX5dIOl4w2N39F+C+8k3HhBAXFPoFnRCZoGAXIhMU7EJkgoJdiExQsAuRCV3f/onVXzz+x92038SedFbQpvV8SyAgKPAX9Iq2f2Ki3KbXvZb2qU9zOenarXxLpnqd+18x7uMakrE1uIkfr1y/mtpKwRZbBTehGE5nxD03O879qAYC1RYur03WeBbjQDVdPHI82LpqimwZBQB95LwAoAiKPRZNXpR0al36NVt11au4H0dfTLZbIB3rzi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhM6Kr0Vq2UsfGitHQxcTItJQCA79+TbL/k2tfwsfqC3PkpLoMEShOmp2aS7f2BmGdB8cJmiRchbDp3ZL7Ex2PSoQf7kHkgNyLwI9LeSiR3anaCS2/VPr7HWm2Ev56zc3wfu0ZjPtleOL/PNQoul9aDvd7KwTT2V3monSH7HF79mmtpn2YpPfdVIjUCurMLkQ0KdiEyQcEuRCYo2IXIBAW7EJnQ1dX4RqOB06fSdddGhvhqcf9psnXRwUO0z+pLeRJB0/lpV6p81bfSSK/iz07y+mhR8TELjKUyT2jwwAaaJMPPuVzi7/ke1KDrZDW+XETV2LiPzUDxaDYD/4n7YdJK4MdcUFMQBfex0uDnXUW6XuJQwV/n548lizmj0eBqge7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyIQFpTczuwzAN9HaktkB7HT3L5vZ3QA+CuBY+6mfcveHomPVmwUOnZxK2gYrXGYYmU5LPHv+sI/2eeYoT7iorFpDbf0D3DY/k064mAm2JioF2/FE9Fd5ksyA8blqbc2X8COQmqIElMZ8OpEEALzJZTkmvQU5PGiG9f+4/1ECSgPpa6cevCxBeTo0g/mIkqi8zvv1VdOv51xwKz76Ylp2jhJ1FqOzNwB80t1/a2YjAB4zs5+2bV9y939ZxDGEED1mMXu9HQZwuP14wsx2A0jv2ieEuGA5r+/sZrYVwBsAPNpuutPMdpnZPWbGt74UQvScRQe7mdUAfA/AJ9z9DICvArgKwI1o3fm/QPrtMLNRMxttNoKfXgohVpRFBbuZVdEK9G+5+/cBwN2PunvT3QsAXwNwc6qvu+90923uvq0cLMIJIVaWBYPdWsu7Xwew292/eE775nOe9n4ATy2/e0KI5WIxq/FvAfBhAE+a2ePttk8B+JCZ3YiWHLcfwMcWOlC52o9Vl6S3ciqCOmKopTPiJuv8ver4kZPU5qf5WKUSl+ycZF7NNdK16QCgCDKhikC6Klf4S1Mi8hqwQD05drxAHoyyqCw4tzKT3qI0wCCLrj/Qw2yez2OjTPwItpoqNblM1gykrf4KlzCbs/waGSCv59AwzwQtkz7BpbGo1fhfIJ2oGWrqQogLC/2CTohMULALkQkKdiEyQcEuRCYo2IXIhK4WnKxU+7B+U/pn9fNTc7SfDad/jDMQSBOXV9JF/ACgCLbiMec//GnOpn2sB6phEchJ0eyXgh8gzQe/TQrH6wAPthOqBJJdtZQ+OSbJAUA5SImrBr++nD6RLmIKAOWR9HVQHuRZhQjGKkjRUSDOzMNQNB7Jpgzk6IH+9LUfZTfqzi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhM6Kr0VjLDcD+RZJpckqkT6a28hstrNSJNAAAqUfFCLv/Up0lhwFk+jVEWWmSrlAN5MEhtKjwtvRXNTiW5YD+3wP9qOT3HlaBYple4rFXMcGm26OMS1TCR3opBfg00mtzHIsi09CafD6sHRUJJkt1cnR9vw4aNyfZKICvrzi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhM6Kr0ZuYoWzqjyPq47OIkG6rR5MX/GkWQ/dPktihrbK5Iyz9TTS79RMeLJLRSUGCxVJx/wclYegskQAS1/oOCmY1yWmrq6wuyv+aDzMcgA2x4iMtaawfTWXuB0os5Il8CQL0I5MFgPmZnJqltdX/ax74qP95gJT2PpeD+rTu7EJmgYBciExTsQmSCgl2ITFCwC5EJC67Gm9kAgEcA9Lef/113/4yZXQngPgAXAXgMwIfdne+bg9Y7yyBJkJiYnub9WKJJk6+M1oPEiVIpWo3nK9NNUn+sWg9WaJe5JhwAWPAeTReZg/OyYDW+5FzxiOYfZDUejUCdKPhYlWBXq0owH4NEeWkEK+f14FqcPsXr3UWr8fV5HhqNWi3ZXg6ONzM1lfah4H0Wc2efA/AOd78Bre2ZbzOzNwH4HIAvufvVAE4B+MgijiWE6BELBru3OCsSVtv/HMA7AHy33X4vgPetiIdCiGVhsfuzl9s7uI4B+CmA5wCcdvezn+MOAkjXiBZCXBAsKtjdvenuNwK4FMDNAF672AHMbIeZjZrZ6Gywba0QYmU5r9V4dz8N4GcA3gxgjZmdXTm7FMAh0menu29z920DA0H1GCHEirJgsJvZxWa2pv14EMC7AexGK+j/pv20OwD8YKWcFEIsncUkwmwGcK+ZldF6c7jf3f/HzJ4BcJ+Z/TOA3wH4+kIHGhmu4R1v+ouk7cjJ44GXaRknSiQJbXykQIQCla+i4yGo07ZAT94r2OKHUQR+WGArW+B/B+dWDmTPBgKZL/CjHLhRpnPF574ZnFckpYZJT8F4fWQbreh4zMVf/vpR2mfBYHf3XQDekGjfh9b3dyHEKwD9gk6ITFCwC5EJCnYhMkHBLkQmKNiFyASLtiBa9sHMjgF4vv3negCB3tY15MdLkR8v5ZXmxxXufnHK0NVgf8nAZqPuvq0ng8sP+ZGhH/oYL0QmKNiFyIReBvvOHo59LvLjpciPl/In40fPvrMLIbqLPsYLkQk9CXYzu83MnjWzvWZ2Vy98aPux38yeNLPHzWy0i+PeY2ZjZvbUOW3rzOynZran/f/aHvlxt5kdas/J42b2ni74cZmZ/czMnjGzp83s79rtXZ2TwI+uzomZDZjZr83sibYf/9Ruv9LMHm3HzXfMLNhLK4G7d/UfgDJaZa1eBaAPwBMAruu2H21f9gNY34Nx3wbgJgBPndP2eQB3tR/fBeBzPfLjbgD/0OX52AzgpvbjEQB/AHBdt+ck8KOrc4JW/m2t/bgK4FEAbwJwP4APttv/DcDfns9xe3FnvxnAXnff563S0/cBuL0HfvQMd38EwMmXNd+OVuFOoEsFPIkfXcfdD7v7b9uPJ9AqjrIFXZ6TwI+u4i2WvchrL4J9C4AD5/zdy2KVDuAnZvaYme3okQ9n2ejuh9uPjwDY2ENf7jSzXe2P+Sv+deJczGwrWvUTHkUP5+RlfgBdnpOVKPKa+wLddne/CcBfA/i4mb2t1w4BrXd2LFA0ZwX5KoCr0Noj4DCAL3RrYDOrAfgegE+4+5lzbd2ck4QfXZ8TX0KRV0Yvgv0QgMvO+ZsWq1xp3P1Q+/8xAA+gt5V3jprZZgBo/z/WCyfc/Wj7QisAfA1dmhMzq6IVYN9y9++3m7s+Jyk/ejUn7bHPu8groxfB/hsA17RXFvsAfBDAg912wsyGzWzk7GMAtwJ4Ku61ojyIVuFOoIcFPM8GV5v3owtzYq2CgV8HsNvdv3iOqatzwvzo9pysWJHXbq0wvmy18T1orXQ+B+Afe+TDq9BSAp4A8HQ3/QDwbbQ+DtbR+u71EbT2zHsYwB4A/wtgXY/8+A8ATwLYhVawbe6CH9vR+oi+C8Dj7X/v6facBH50dU4AvB6tIq670Hpj+fQ51+yvAewF8F8A+s/nuPoFnRCZkPsCnRDZoGAXIhMU7EJkgoJdiExQsAuRCQp2ITJBwS5EJijYhciE/wdtN+FyjcOEpwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsS9fZlNNnPE"
      },
      "source": [
        "#### Building net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvIjZcN8IhbC"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    # Convolutional layer #1\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
        "\n",
        "    # Convolutional layer #2\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
        "\n",
        "    # Convolutional layer #3\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Convolutional layer #4\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Convolutional layer #5\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "\n",
        "    # Fully-connected layer #1\n",
        "    keras.layers.Dense(4096, activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Fully-connected layer #2\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Fully-connected layer #3\n",
        "    keras.layers.Dense(1000, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Output layer\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kvvFUHVn1Lj",
        "outputId": "778e180e-4a01-4193-b714-bdaac10885ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        }
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 6, 6, 96)          384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 3, 3, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 3, 3, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 25,693,698\n",
            "Trainable params: 25,690,946\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxnZfkWcOgTa"
      },
      "source": [
        "### Training net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJJJHH7jKcaW",
        "outputId": "b1a51f83-9685-4ec4-ecf9-9912a19f98fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=150, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1896 - accuracy: 0.2005 - val_loss: 1.8117 - val_accuracy: 0.3412\n",
            "Epoch 2/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8223 - accuracy: 0.3178 - val_loss: 1.7021 - val_accuracy: 0.3896\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.6504 - accuracy: 0.3899 - val_loss: 1.5285 - val_accuracy: 0.4503\n",
            "Epoch 4/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5365 - accuracy: 0.4343 - val_loss: 1.7035 - val_accuracy: 0.4139\n",
            "Epoch 5/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4459 - accuracy: 0.4722 - val_loss: 1.4383 - val_accuracy: 0.4898\n",
            "Epoch 6/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3764 - accuracy: 0.5026 - val_loss: 1.3718 - val_accuracy: 0.5012\n",
            "Epoch 7/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3029 - accuracy: 0.5315 - val_loss: 1.3428 - val_accuracy: 0.5119\n",
            "Epoch 8/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2489 - accuracy: 0.5519 - val_loss: 1.3012 - val_accuracy: 0.5264\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1890 - accuracy: 0.5745 - val_loss: 1.2358 - val_accuracy: 0.5560\n",
            "Epoch 10/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1340 - accuracy: 0.5949 - val_loss: 1.3101 - val_accuracy: 0.5431\n",
            "Epoch 11/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0857 - accuracy: 0.6108 - val_loss: 1.3065 - val_accuracy: 0.5510\n",
            "Epoch 12/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0201 - accuracy: 0.6373 - val_loss: 1.1721 - val_accuracy: 0.5969\n",
            "Epoch 13/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9789 - accuracy: 0.6528 - val_loss: 1.3047 - val_accuracy: 0.5516\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9254 - accuracy: 0.6714 - val_loss: 1.2245 - val_accuracy: 0.5832\n",
            "Epoch 15/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8661 - accuracy: 0.6903 - val_loss: 1.2293 - val_accuracy: 0.5907\n",
            "Epoch 16/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8112 - accuracy: 0.7090 - val_loss: 1.2427 - val_accuracy: 0.5876\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7587 - accuracy: 0.7287 - val_loss: 1.3038 - val_accuracy: 0.5847\n",
            "Epoch 18/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7005 - accuracy: 0.7501 - val_loss: 1.2667 - val_accuracy: 0.6078\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6481 - accuracy: 0.7686 - val_loss: 1.3647 - val_accuracy: 0.5695\n",
            "Epoch 20/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5933 - accuracy: 0.7894 - val_loss: 1.3316 - val_accuracy: 0.6010\n",
            "Epoch 21/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5484 - accuracy: 0.8033 - val_loss: 1.4011 - val_accuracy: 0.5948\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4976 - accuracy: 0.8211 - val_loss: 1.5446 - val_accuracy: 0.5872\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4588 - accuracy: 0.8358 - val_loss: 1.5047 - val_accuracy: 0.5913\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4133 - accuracy: 0.8508 - val_loss: 1.4744 - val_accuracy: 0.6081\n",
            "Epoch 25/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.3709 - accuracy: 0.8679 - val_loss: 1.8886 - val_accuracy: 0.5774\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.3430 - accuracy: 0.8764 - val_loss: 1.7157 - val_accuracy: 0.5962\n",
            "Epoch 27/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.3166 - accuracy: 0.8868 - val_loss: 1.7619 - val_accuracy: 0.5912\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2781 - accuracy: 0.9019 - val_loss: 1.9966 - val_accuracy: 0.5575\n",
            "Epoch 29/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2576 - accuracy: 0.9090 - val_loss: 1.8658 - val_accuracy: 0.5821\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2352 - accuracy: 0.9166 - val_loss: 1.9737 - val_accuracy: 0.5890\n",
            "Epoch 31/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2192 - accuracy: 0.9239 - val_loss: 1.9261 - val_accuracy: 0.5954\n",
            "Epoch 32/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1931 - accuracy: 0.9317 - val_loss: 1.9825 - val_accuracy: 0.5995\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1781 - accuracy: 0.9374 - val_loss: 2.0854 - val_accuracy: 0.5865\n",
            "Epoch 34/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1629 - accuracy: 0.9439 - val_loss: 2.2935 - val_accuracy: 0.5701\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1522 - accuracy: 0.9475 - val_loss: 2.2644 - val_accuracy: 0.5875\n",
            "Epoch 36/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1384 - accuracy: 0.9520 - val_loss: 2.0369 - val_accuracy: 0.6148\n",
            "Epoch 37/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1288 - accuracy: 0.9555 - val_loss: 2.1265 - val_accuracy: 0.6127\n",
            "Epoch 38/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1150 - accuracy: 0.9610 - val_loss: 2.1261 - val_accuracy: 0.6152\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1133 - accuracy: 0.9613 - val_loss: 2.3997 - val_accuracy: 0.5720\n",
            "Epoch 40/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1026 - accuracy: 0.9655 - val_loss: 2.1721 - val_accuracy: 0.6133\n",
            "Epoch 41/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1057 - accuracy: 0.9635 - val_loss: 2.2309 - val_accuracy: 0.6043\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0912 - accuracy: 0.9697 - val_loss: 2.4487 - val_accuracy: 0.5805\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0897 - accuracy: 0.9702 - val_loss: 2.2635 - val_accuracy: 0.6079\n",
            "Epoch 44/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0825 - accuracy: 0.9720 - val_loss: 2.2755 - val_accuracy: 0.6120\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0779 - accuracy: 0.9730 - val_loss: 2.3947 - val_accuracy: 0.5974\n",
            "Epoch 46/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0721 - accuracy: 0.9756 - val_loss: 2.4022 - val_accuracy: 0.6021\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0657 - accuracy: 0.9778 - val_loss: 2.3537 - val_accuracy: 0.6134\n",
            "Epoch 48/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 2.4990 - val_accuracy: 0.6069\n",
            "Epoch 49/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 2.4051 - val_accuracy: 0.6190\n",
            "Epoch 50/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0617 - accuracy: 0.9791 - val_loss: 2.4788 - val_accuracy: 0.5932\n",
            "Epoch 51/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 2.3938 - val_accuracy: 0.6065\n",
            "Epoch 52/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 2.4264 - val_accuracy: 0.6096\n",
            "Epoch 53/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0525 - accuracy: 0.9826 - val_loss: 2.4766 - val_accuracy: 0.6088\n",
            "Epoch 54/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 2.4655 - val_accuracy: 0.6210\n",
            "Epoch 55/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 2.5047 - val_accuracy: 0.6136\n",
            "Epoch 56/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0428 - accuracy: 0.9858 - val_loss: 2.4480 - val_accuracy: 0.6193\n",
            "Epoch 57/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0426 - accuracy: 0.9858 - val_loss: 2.5502 - val_accuracy: 0.6162\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 2.4746 - val_accuracy: 0.6193\n",
            "Epoch 59/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0427 - accuracy: 0.9856 - val_loss: 3.3977 - val_accuracy: 0.5636\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 2.4991 - val_accuracy: 0.6276\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 2.5146 - val_accuracy: 0.6199\n",
            "Epoch 62/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 2.5792 - val_accuracy: 0.6188\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 2.6315 - val_accuracy: 0.6117\n",
            "Epoch 64/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 2.5175 - val_accuracy: 0.6246\n",
            "Epoch 65/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 2.5181 - val_accuracy: 0.6274\n",
            "Epoch 66/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 2.6052 - val_accuracy: 0.6250\n",
            "Epoch 67/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 2.5941 - val_accuracy: 0.6223\n",
            "Epoch 68/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 2.6173 - val_accuracy: 0.6244\n",
            "Epoch 69/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 2.6428 - val_accuracy: 0.6169\n",
            "Epoch 70/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 2.6413 - val_accuracy: 0.6179\n",
            "Epoch 71/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 2.7026 - val_accuracy: 0.6255\n",
            "Epoch 72/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 2.8834 - val_accuracy: 0.6050\n",
            "Epoch 73/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 3.1734 - val_accuracy: 0.5755\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 2.6026 - val_accuracy: 0.6225\n",
            "Epoch 75/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 2.6369 - val_accuracy: 0.6266\n",
            "Epoch 76/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 2.6136 - val_accuracy: 0.6281\n",
            "Epoch 77/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 2.6099 - val_accuracy: 0.6277\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 2.6450 - val_accuracy: 0.6273\n",
            "Epoch 79/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 2.8336 - val_accuracy: 0.6139\n",
            "Epoch 80/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 2.7416 - val_accuracy: 0.6228\n",
            "Epoch 81/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 2.7488 - val_accuracy: 0.6260\n",
            "Epoch 82/150\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 2.7265 - val_accuracy: 0.6274\n",
            "Epoch 83/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 2.7866 - val_accuracy: 0.6185\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 2.9072 - val_accuracy: 0.6188\n",
            "Epoch 85/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 2.6852 - val_accuracy: 0.6282\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 2.7820 - val_accuracy: 0.6153\n",
            "Epoch 87/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 2.7528 - val_accuracy: 0.6331\n",
            "Epoch 88/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 2.8108 - val_accuracy: 0.6256\n",
            "Epoch 89/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 2.8042 - val_accuracy: 0.6192\n",
            "Epoch 90/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 2.9571 - val_accuracy: 0.6008\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 2.7507 - val_accuracy: 0.6245\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 2.8544 - val_accuracy: 0.6155\n",
            "Epoch 93/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 2.7032 - val_accuracy: 0.6279\n",
            "Epoch 94/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 2.7343 - val_accuracy: 0.6280\n",
            "Epoch 95/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 2.8015 - val_accuracy: 0.6175\n",
            "Epoch 96/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 2.7299 - val_accuracy: 0.6235\n",
            "Epoch 97/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 3.2365 - val_accuracy: 0.5877\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 2.8029 - val_accuracy: 0.6278\n",
            "Epoch 99/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 2.7802 - val_accuracy: 0.6291\n",
            "Epoch 100/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 2.7548 - val_accuracy: 0.6280\n",
            "Epoch 101/150\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 2.7309 - val_accuracy: 0.6235\n",
            "Epoch 102/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 2.9581 - val_accuracy: 0.6173\n",
            "Epoch 103/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 2.8764 - val_accuracy: 0.6205\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 2.8285 - val_accuracy: 0.6241\n",
            "Epoch 105/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 2.7943 - val_accuracy: 0.6303\n",
            "Epoch 106/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 2.8495 - val_accuracy: 0.6263\n",
            "Epoch 107/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 2.8254 - val_accuracy: 0.6230\n",
            "Epoch 108/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 2.8359 - val_accuracy: 0.6252\n",
            "Epoch 109/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 2.8901 - val_accuracy: 0.6214\n",
            "Epoch 110/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 2.8237 - val_accuracy: 0.6236\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 2.8686 - val_accuracy: 0.6294\n",
            "Epoch 112/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 2.8303 - val_accuracy: 0.6336\n",
            "Epoch 113/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 2.8726 - val_accuracy: 0.6273\n",
            "Epoch 114/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 2.9992 - val_accuracy: 0.6207\n",
            "Epoch 115/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 2.9081 - val_accuracy: 0.6297\n",
            "Epoch 116/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 2.8058 - val_accuracy: 0.6323\n",
            "Epoch 117/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 2.9290 - val_accuracy: 0.6265\n",
            "Epoch 118/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 2.9027 - val_accuracy: 0.6329\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 2.8971 - val_accuracy: 0.6385\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 2.8833 - val_accuracy: 0.6322\n",
            "Epoch 121/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 2.8527 - val_accuracy: 0.6350\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 2.8347 - val_accuracy: 0.6287\n",
            "Epoch 123/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 2.8909 - val_accuracy: 0.6298\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 2.8875 - val_accuracy: 0.6285\n",
            "Epoch 125/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 2.9233 - val_accuracy: 0.6243\n",
            "Epoch 126/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 2.9195 - val_accuracy: 0.6301\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 2.9770 - val_accuracy: 0.6259\n",
            "Epoch 128/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 2.8541 - val_accuracy: 0.6373\n",
            "Epoch 129/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 2.9738 - val_accuracy: 0.6283\n",
            "Epoch 130/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 2.9070 - val_accuracy: 0.6312\n",
            "Epoch 131/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 2.9044 - val_accuracy: 0.6242\n",
            "Epoch 132/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 2.9868 - val_accuracy: 0.6213\n",
            "Epoch 133/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 2.9550 - val_accuracy: 0.6225\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 2.8459 - val_accuracy: 0.6342\n",
            "Epoch 135/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 2.9193 - val_accuracy: 0.6307\n",
            "Epoch 136/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 2.9713 - val_accuracy: 0.6183\n",
            "Epoch 137/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 2.9038 - val_accuracy: 0.6288\n",
            "Epoch 138/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 3.0329 - val_accuracy: 0.6221\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 2.9243 - val_accuracy: 0.6277\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 2.9183 - val_accuracy: 0.6323\n",
            "Epoch 141/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 2.9048 - val_accuracy: 0.6372\n",
            "Epoch 142/150\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 2.9484 - val_accuracy: 0.6331\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 3.0039 - val_accuracy: 0.6249\n",
            "Epoch 144/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 2.9731 - val_accuracy: 0.6261\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 2.9439 - val_accuracy: 0.6318\n",
            "Epoch 146/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 2.9676 - val_accuracy: 0.6301\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 3.2619 - val_accuracy: 0.5911\n",
            "Epoch 148/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 2.9380 - val_accuracy: 0.6333\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 3.1405 - val_accuracy: 0.6166\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 2.9550 - val_accuracy: 0.6359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fe6053748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jd2hZMSjAXf"
      },
      "source": [
        "### Plotting losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY96PPbFisq1"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKx1J2LHiptR",
        "outputId": "7f042f35-b27b-4fbc-f9c2-e2ab0a72f38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4f30e9f1d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}